\documentclass{elsarticle}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{url}
\usepackage{booktabs}
\usepackage{pslatex}
\usepackage{setspace}
\usepackage{subcaption}
\usepackage[colorlinks=true,citecolor=blue]{hyperref}

\DeclareMathSymbol{\Gamma}{\mathalpha}{operators}{0}
\DeclareMathSymbol{\Delta}{\mathalpha}{operators}{1}
\DeclareMathSymbol{\Theta}{\mathalpha}{operators}{2}
\DeclareMathSymbol{\Lambda}{\mathalpha}{operators}{3}
\DeclareMathSymbol{\Xi}{\mathalpha}{operators}{4}
\DeclareMathSymbol{\Pi}{\mathalpha}{operators}{5}
\DeclareMathSymbol{\Sigma}{\mathalpha}{operators}{6}
\DeclareMathSymbol{\Upsilon}{\mathalpha}{operators}{7}
\DeclareMathSymbol{\Phi}{\mathalpha}{operators}{8}
\DeclareMathSymbol{\Psi}{\mathalpha}{operators}{9}
\DeclareMathSymbol{\Omega}{\mathalpha}{operators}{10}
\newcommand{\transpose}{^\mathrm{T}}
\newcommand{\GM}{\mathrm{GM}}
\newcommand{\WM}{\mathrm{WM}}
\newcommand{\CSF}{\mathrm{CSF}}
\newcommand{\ra}[1]{\renewcommand{\arraystretch}{#1}}


\def\naive{na\"{\i}ve }





\begin{document}
\begin{frontmatter}
\title{Decomposing cerebral blood flow MRI into functional and structural components:  A non-local approach based on prediction}
\author[picsl,be]{Benjamin M. Kandel}
\ead{bkandel@seas.upenn.edu}
\author[neuro,rad]{John A. Detre}
\author[picsl,rad]{James C. Gee}
\author[picsl,rad]{Brian B. Avants}
\address[picsl]{Penn Image Computing and Science Laboratory, University of Pennsylvania, Philadelphia, PA}
\address[neuro]{Department of Neurology, Hospital of the University of Pennsylvania, Philadelphia, PA}
\address[rad]{Department of Radiology, Hospital of the University of Pennsylvania, Philadelphia, PA}
\address[be]{Department of Bioengineering, University of Pennsylvania, Philadelphia, PA}


\begin{abstract}
We propose a flexible and widely applicable method for adjusting arterial spin labeling (ASL) perfusion images based on the underlying anatomy.  Using learned patch-based, rotation invariant descriptors of the anatomical image, we learn a global relation between brain anatomy and the corresponding perfusion image.  This relation allows us to produce an image of perfusion that would be predicted given only the underlying anatomy and a second image that retains perfusion information that cannot be predicted by anatomical features.  This decomposition of the perfusion image allows for an adjustment of perfusion imaging for the underlying anatomy that relies on minimal prior knowledge.  Our learned structural images account for much more variance explained than can be predicted using only gray and white matter probability maps, which are the input to standard partial volume correction techniques.  Studies in test-retest data show that both the anatomically predicted and residual perfusion signal are highly replicable for a given subject.  In addition, studies in a pediatric population demonstrate that the anatomically predicted and residual perfusion images are tightly linked to age, highlighting the biological validity of the obtained values.  
\end{abstract}

\end{frontmatter}


\section{Introduction}

<<setup, echo=FALSE, cache=FALSE>>=
## numbers >= 10^5 will be denoted in scientific notation,
## and rounded to 2 digits
options(digits = 2, scipen=-1)
opts_chunk$set(echo=FALSE)
booleval <- FALSE
@

Many modalities of medical imaging contain information that can be partially captured by other modalities.  For example, perfusion of the brain is partially determined by the structure of the brain, which is in turn captured by T1 or other structural imaging modalities \cite{villain_relationships_2008,chetelat_direct_2008}; and conversely, brain perfusion may contribute to cortical thickness patterns \cite{fierstra_steal_2010} and T1 imaging maps \cite{salgado-pineda_brain_2006,franklin_vbm_2013}.  To improve interpretability of perfusion images, it is common to correct the image for information contained in the structural image.  In particular, many perfusion image processing protocols correct the perfusion image for partial voluming effects.  In addition to partial volume and other technical challenges, though, perfusion in a given voxel may be at least partially determined by the underlying brain anatomy.  Therefore, we seek to reframe this relation between brain anatomy and perfusion more broadly:  Given a perfusion image and a structural anatomical image, how much information is unique to the perfusion image, and how much of the perfusion image can be reconstructed given the structural image? 

As a motivating example problem, we consider perfusion measurements of normally developing adolescents.  Perfusion studies of normally developing children have shown changes over development \cite{chiron_changes_1992,wintermark_brain_2004,biagi_age_2007,jain_longitudinal_2012,satterthwaite_functional_2013,wang_pediatric_2003,wang_pediatric_2006} .  In parallel, many studies have focused on structural brain changes over development, including such metrics as cortical thickness \cite{shaw_neurodevelopmental_2008} and white matter structure \cite{tamnes_brain_2010}.  Some of the changes in perfusion are likely due to development of the underlying anatomical substrate, including such developments as cortical thickness, gyrification indices \cite{blanton_mapping_2001,su_geometric_2013}, and possibly other, more subtle anatomical changes.On the other hand, it is possible that some of the changes in perfusion are due only to changes in the perfusion of specific cortical areas that are not explained by structural changes.  We seek to improve the interpretability of perfusion imaging by separating the component of cortical perfusion that can be explained by structural features from the component of cortical perfusion that is due to biological processes that are not driven by the underlying anatomy.  This separation will help evaluate what unique information is gained by using perfusion imaging as compared to anatomical imaging modalities, thus enabling more principled and informative integration of perfusion imaging into multimodal neuroimaging population studies. The residual perfusion signal represents localized processes that are not explained by the global anatomy-perfusion relationship, possibly signifying development of functional brain networks.  

Several image processing strategies incorporate knowledge of one modality to improve the interpretability of a second modality, especially where the two modalities offer complementary sources of information.  One of the most commonly encountered variants of this problem occurs in positron emission tomograpy (PET) image processing.  PET images have low spatial resolution, leading to significant partial volume effects (PVE) \cite{hoffman_quantitation_1979}.  A widespread method for correcting these partial volume effects is to divide the PET image by gray and white matter probability images (e.g., \cite{muller-gartner_measurement_1992}).  By assuming that PET activity within white matter is known, it is then possible to reconstruct the amount of signal that would have resulted from a purely gray matter voxel.  Similar strategies have been pursued for arterial spin labeling (ASL) perfusion \cite{williams_magnetic_1992} partial volume corrections.  Many ASL partial volume correction methods assume that white matter has perfusion that is 40\% of a comparable unit of gray matter \cite{johnson_pattern_2005}, based on quantitative \textit{in vivo} measures of ASL perfusion \cite{roberts_quantitative_1994}.  More sophisticated models include partial volume corrections based on locally determined gray matter activation \cite{asllani_regression_2008,asllani_separating_2009}, a kinetic equation for multiple inversion time ASL \cite{chappell_partial_2011}, and specially designed pulse sequences \cite{petr_partial_2012}.  In addition, some studies have incorporated the presence of brain lesions for partial volume correction of ASL images \cite{schuff_cerebral_2009}.  

\begin{figure}
\centering
\makebox[\textwidth][c]{\includegraphics[width = 13cm]{figure/ASL_Structure_Function_Flowchart.pdf}}
\caption{Graphical abstract of proposed method.  Patches are sampled from image in modality 1 (here, T1) and eigendecomposition is used to learn optimal features (``eigenpatches'') to describe patches.  Patches corresponding to each point in the image are then projected onto the ``eigenpatches'' to create a representation of the input image in feature space.  We then use linear regression to predict the second image (here, perfusion image) from the feature-based description of the first image.  This enables us to decompose the perfusion image into a component that is predicted from the structural image and the unique contribution of the perfusion image.}
\label{fig:flowchart}
\end{figure}

Fundamentally, partial volume correction aims to reconstruct the ideal image that the scanner would have seen had technical impediments, such as scanner resolution and point spread function, not interfered with the imaging.  Although this correction is an important consideration when interpreting perfusion images, it only partially accounts for the effects of underlying brain structure.  Besides technical difficulties with obtaining accurate perfusion measurements, there may be genuine interactions between the underlying anatomy and the observed perfusion that go beyond white and gray matter probabilities.  Position along a sulcus, cortical curvature and thickness, and cortical folding patterns may also contribute to the observed perfusion value.  

Generating a feature vector for each voxel that contains all the necessary information to reconstruct perfusion from anatomy is not straightforward.  Gray matter and white matter probabilities are nearly always used when predicting perfusion from anatomical imaging.  
Cortical thickness may also be correlated to perfusion.  In addition to these features, we propose learning anatomical features implicitly from the anatomical image to predict perfusion.  We learn a dictionary of anatomical patch features that can be used to predict perfusion, with the atoms, or elements, in the dictionary corresponding to paradigmatic textural and anatomical features. In contrast to traditional dictionary learning approaches, we construct rotation-invariant dictionaries to enable more complete sharing between similar anatomical structures across the brain.  This rotation invariance allows, for example, sharing of information between right and left sides of the brain, which would not be possible when using traditional dictionary learning techniques. Rotation invariance is particularly important in 3D images, as the number of possible orientations increases exponentially with the number of dimensions. Projecting patches focused at every voxel in the image onto the rotation invariant dictionary produces a feature weight image for each atom, in the dictionary.  We combine the structural feature weights with the probabilitistic segmentation images in a linear model to predict perfusion from the structurally derived measures.  This linear model then produces a ``structural'' perfusion image, corresponding to the predicted perfusion given the structural features, and a residual  perfusion image, corresponding to the perfusion that cannot be explained by structural information.   A graphical abstract of our method is shown in Figure \ref{fig:flowchart}.   

The method we use to construct the feature representation of the input image is inspired by feature learning methods \cite{ranzato_unsupervised_2007,aharon_k-svd:_2006,mairal_discriminative_2008}; rotation-invariant feature transforms \cite{lowe_object_1999,ke_pca-sift:_2004,bay_surf:_2006,toews_efficient_2013} and dictionary learning methods \cite{chen_rotation_2012,barthelemy_shift_2012};  and modality synthesis algorithms \cite{hertzmann_image_2001,wang_deringing_2006,rueda_single-image_2013,rousseau_non-local_2010}.  To the best of our knowledge, this work is the first to use rotation invariance for image synthesis.  In addition, our work uses a much more expressive and accurate model for predicting CBF from structural information than prior work.  



In sum, we make the following contributions: 1) We propose a novel rotation-invariant dictionary learning method for modality synthesis;  2) We show that these learned dictionaries are significantly better at predicting perfusion than segmentation probability or cortical thickness maps; 3) We demonstrate that this method produces consistent perfusion maps across session scans within a single subject; 4) We show that this method decomposes a noisy raw CBF signal into structural and functional CBF signals, each of which has lower variance over a pediatric population than the original raw CBF image; and 5) The change in the perfusion image not predicted by signal tends to be greatest over development in precuneus and temporal pole, two characteristic regions in the default mode network.  

\section{Methods}
\subsection{Representations of Structure}
\label{sec:struct}
Given an image $\mathcal{I}$, we denote the segmentation probability for white matter (WM) and gray matter (GM) at a voxel $x \in \mathcal{I}$ as $p_{\mathrm{GM,WM}}(x)$.  We additionally denote the observed cerebral blood flow (CBF) value as $c_{\mathrm{obs}}(x)$, and the corrected CBF value as $c_{\mathrm{corr}}(x)$.  Standard ASL partial volume correction \cite{johnson_pattern_2005} takes the form 
\begin{equation}
c_{\mathrm{corr}}(x) = \frac{c_{\mathrm{obs}}(x)}{p_{\mathrm{GM}}(x) + 0.4 \cdot p_{\mathrm{WM}}(x)}.
\label{eqn:pve_correction} 
\end{equation}
This specific formulation derives from a more general assumption of a linear relationship between the voxelwise white matter and gray matter densities.  Denoting the true GM and WM CBF levels at voxel $x$ as $c_{\mathrm{GM,WM}}(x)$, we have 
\begin{equation}
c_{\mathrm{GM}}(x) \cdot p_{\mathrm{GM}}(x) + c_{\mathrm{WM}}(x) \cdot p_{\mathrm{WM}}(x) = c_{\mathrm{obs}}(x),
\end{equation}
where assuming that $c_{\mathrm{WM}}(x)=0.4 \cdot c_{\mathrm{GM}}(x)$ leads to Equation \ref{eqn:pve_correction}.  Alternatively, it is possible to learn the relation between GM and WM activity from the CBF image directly, either by sampling over lobes \cite{johnson_pattern_2005} or a local kernel centered on the voxel of interest \cite{asllani_regression_2008}.    Both approaches directly analyze the gray matter and white matter probability images as they relate to perfusion.  

As explained in the Introduction, we take a decidedly different approach to incorporating anatomy into CBF analysis.  Instead of attempting to infer the unobservable true GM and WM perfusion in a voxelwise manner, we use all available anatomical information to create a ``best guess'' at what the observed perfusion would be given the anatomy at voxel $x$.  Formulated as a prediction problem, we have 
\begin{equation}
c_{\mathrm{obs}}(x) = p_{\mathrm{GM}}(x) \beta_{\mathrm{GM}} + p_{\mathrm{WM}}(x) \beta_{\mathrm{WM}} + \mathrm{residual}(x),
\end{equation}
where we have replaced $c_{\mathrm{GM,WM}}(x)$ with $\beta_{\mathrm{GM,WM}}$ to emphasize that they are learned values that are constant across the image.  The ``$\mathrm{residual}(x)$'' term accounts for the observed perfusion that cannot be accounted for by the other predictors. In addition to the tissue membership probability values, we incorporate a structural feature vector that describes the anatomy surrounding the voxel of interest.  Denoting the value of the $n$'th feature of voxel $x$ as $s_n(x), n \in \lbrace 1, \ldots, k \rbrace$, we obtain 
\begin{equation}
c_{\mathrm{obs}}(x) = p_{\mathrm{GM}}(x) \beta_{\mathrm{GM}} + p_{\mathrm{WM}}(x) \beta_{\mathrm{WM}} + s_1(x) \beta_1 + \ldots + s_k(x) \beta_k + \mathrm{residual}(x),
\label{eqn:feature_predict}
\end{equation}
where $\beta_n$ is the weight for the $n$'th feature.  As before, the $\beta_n$ weights are learned over the entire image.  Concatenating the anatomically derived predictors for voxel $x$ on the right hand side of Equation \ref{eqn:feature_predict} as $X_x=[p_{\mathrm{GM}}(x), p_{\mathrm{WM}}(x), s_1(x), \ldots s_k(x)]$ and the weights as $\boldsymbol{\beta} = [\beta_{\mathrm{GM}}, \beta_{\mathrm{WM}}, \beta_1, \ldots, \beta_k]^{\mathrm{T}}$ allows us to reformulate Equation \ref{eqn:feature_predict} as a standard linear regression: 
\begin{equation}
c_{\mathrm{obs}}(x) = X_x \boldsymbol{\beta} + \epsilon,
\end{equation}
where the $\epsilon$ term corresponds to the $\mathrm{residual}(x)$ term in Equation \ref{eqn:feature_predict}.  Unlike in standard linear regression, the $\epsilon$ term here is \textit{not} i.i.d. Gaussian noise; it corresponds to the component of perfusion imaging that cannot be predicted from anatomical information.  (We recall that the optimality of the $\beta$ coefficients obtained from minimizing the objective $\|Y - X \beta\|^2$ does not make any assumptions about the structure of the residual term.)  Further concatenating the observed CBF value across the image as $C_{\mathrm{obs}} = [c_{\mathrm{obs}}(1), \ldots, c_{\mathrm{obs}}(m)]$, where there are $m$ voxels in the image, and (using Matlab notation) $X=[X_1; \ldots; X_m]$, we obtain 
\begin{equation}
C_{\mathrm{obs}} = X \boldsymbol{\beta} + \epsilon.
\end{equation}
The $X \boldsymbol{\beta}$ term corresponds to the component of perfusion that can be predicted from anatomical features, and the $\epsilon$ term corresponds to the component of perfusion that cannot be predicted from anatomical features.  A greater correlation between $C_{\mathrm{obs}}$ and $X \boldsymbol{\beta}$ indicates a more accurate reconstruction of observed perfusion from anatomical features.

\subsection{Dictionary Construction}
To generate the structural feature matrix, we first construct a rotation-invariant dictionary of ``eigenpatches.'' For computational feasibility, we take a random sampling of 1000 patches, each of which consist of a sphere of 7 mm diameter, from around the image.  We chose a diameter of 7 mm because that is approximately the scale of the cortical features, such as curvature and position along the gyrus or sulcus, that we are interested in modeling.  We construct a sample patch matrix in which every row is a sample patch and the columns are the vectorized patches.  We mean-center each patch to minimize the effect of intensity inhomogeneity and concurrently emphasize the gradient and texture information.  We then perform an eigendecomposition of that patch matrix and retain enough eigenvectors to account for 95\% of the variance of the sample patch matrix.  The eigenvectors of that matrix are the canonical ``eigenpatches'' that can be used for constructing patch-based descriptors.  

Unlike most traditional dictionary learning methods, we produce a rotation-invariant dictionary.  To achieve rotation invariance, we first reorient all image patches to match the dominant orientations of the first eigenpatch of the sample patch matrix.  The problem of matching the orientation of two vectors has been known as Wahba's problem since it was first posed in the 1960's \cite{wahba_least_1965}, and the analytical solution is known as the Kabsch algorithm \cite{markley_attitude_1988,kabsch_solution_1976}.  The parallel of attitude for satellites in imaging applications is the orientation of the first eigenvector (or two eigenvectors for a 3D image) of the covariance matrix of the gradient of the image.  Denoting the $k$'th eigenvector of the gradient covariance matrix of the reference frame as $w_k$ and the $k$'th eigenvector of the patch to be rotated as $v_k$, we calculate the rotation matrix $Q$ that best aligns them: 
\begin{equation}
\underset{\mathbf{Q}}{\operatorname{arg\,max}} \quad \sum_k \| w_k - \mathbf{Q} v_k \|^2
\label{eqn:wahba}
\end{equation}
Denoting $B = w_k v_k^T$, we compute the singular value decomposition (SVD) of $B$: $B = U S V^\mathrm{T}$.  Then the analytical solution to Equation \ref{eqn:wahba} is given by $\mathbf{Q} = U M V^T$, where M = diag[1 1 det(U) det(V)].  A more computationally expensive alternative is to use the Radon transform to estimate orientation \cite{jafari-khouzani_radon_2005,chen_rotation_2012}.  We reorient each image patch to match the orientation of the first eigenvector of the sample patch matrix, and then take a random sampling of the reoriented patches and take the eigendecomposition of those sampled patches.  As before, we retain enough eigenpatches to account for 95\% of the variance of the patch matrix, corresponding to approximately 100 eigenpatches.  The resulting matrix is an orientation-invariant dictionary that can be used to generate a patch-based descriptor of each patch in the image.  These patch-based descriptors capture salient features of the input anatomical patterns and are therefore more generalizable than using the gray-scale value at each point directly.  

\subsection{Feature Learning}
\label{sec:feature_regression}
Once we have the rotation-invariant dictionary, we project the reoriented patches corresponding to each voxel in the image onto each rotation-invariant eigenpatch.  This gives us an $n \times k$ feature matrix, where $n$ is the number of voxels in the image and $k$ is the number of eigenpatches.  The columns of this feature matrix correspond to the response of each eigenpatch to the patch centered on each voxel.  In addition to the structural feature matrix, we use the GM and WM probabilities for each voxel in the image.  The GM and WM probabilities are usually the two strongest predictors of blood flow in a given voxel, and we have found that they significantly increase the accuracy of CBF prediction. 

Once we have the final structural predictor matrix, we run a linear model relating CBF to our predictor matrix.  In R notation, 
\begin{equation}
\text{CBF signal} \sim \text{GM probability} + \text{WM probability} + \text{Structural predictors}.
\end{equation}
To avoid overfitting, we train the model on 5\% of the image, and then predict on the remaining 95\% of the image.  We note that in the current study, we learned the relationship between brain structure and perfusion on a per-subject basis.    A graphical outline of the method is in Figure \ref{fig:flowchart}, and a more formal description of the algorithm is in Algorithm \ref{alg:eigenpatch}.

\begin{algorithm}
\begin{algorithmic}
\State \textbf{Input}: patch neighborhood operator $N_i$, number of patches to sample $m$, input image $I$, target variance explained $v$. \Comment{$N_i$ defines the points in the neighborhood of voxel $i$.}
\State $n \leftarrow$ number of pixels in $I$.
\State $l \leftarrow$ number of pixels in $N_i$. 
\State Initialize $P$ $\leftarrow$ [ ] \Comment{$n \times l$ patch matrix for every pixel in image.}
\State Initialize $S$ $\leftarrow$ [ ] \Comment{$m \times l$ sample patch matrix.}
\For{$i=0,\ldots,m-1$}
  \State $r \leftarrow$ random voxel in $I$.
  \State $t \leftarrow$ vector representation of $\left\lbrace s : s \in N_r \right\rbrace$ 
  \State $t \leftarrow t - \mathrm{mean}(t)$. \Comment{Mean-center patch.}
  \State $S \leftarrow [P \; t]$.
\EndFor
\For{$i=0, \ldots, n-1$}
  \State $t \leftarrow$ vector representation of $\left\lbrace s:s \in N_i \right\rbrace$. 
  \State $t \leftarrow t - \mathrm{mean}(t)$. 
  \State $P \leftarrow [P \; t]$.
\EndFor
\State Compute eigenvectors $V$ of $P$. 
\For{$i=0, \ldots, n-1$}
  \State Reorient $P_i$ to $V_1$.
\EndFor
\State Recompute eigenvectors $V$ of $P$. 
\State Retain eigenvectors necessary to achieve $v$ variance explained.
\State $F \leftarrow P V$  \Comment{Project patches of input image onto eigenvectors.}
\State \textbf{Output}: $F$.  \Comment{Matrix with response of each image voxel to each eigenpatch.}
\end{algorithmic}
\caption{Algorithm for generating patch-based description of image.}
\label{alg:eigenpatch}
\end{algorithm}

\subsection{Clinical Data}
\subsubsection{Test-Retest Data:} The cohort consists of 12 healthy young adult participants (mean age 25.5$\pm$4.5, 7 female). For each subject, data was acquired at two time points in the same day. For each time point, high resolution T1-weighted anatomic images were obtained using 3D MPRAGE imaging sequence and the following acquisition parameters: TR = 1620 ms, TI = 950 ms, TE = 3 ms, flip angle = $15\,^{\circ}$, 160 contiguous slices of 1.0 mm thickness, FOV = 192 $\times$ 256 mm$^2$, matrix = 192$\times$256, 1 NEX with a scan time of 6 min. The resulting voxel size was 1 mm. Additionally, pseudo-continuous ASL (pCASL) images were aquired with 80 alternating tag/control images and 2 M0 images all with 14 contiguous slice of 7.5mm thickness, FOV = 220 $\times$ 220mm$^2$, matrix = 64 $\times$ 64; TI1 = 700ms, TI2 = 1700ms.

<<data.ped, echo=FALSE, results='hide', eval=TRUE, fig.keep='none'>>=
suppressMessages(library(ggplot2))
suppressMessages(library(reshape2))
data.ped <- read.csv('data/JJ_PEDS_Aug_2013.csv')
nsubj.ped <- nrow(data.ped)
tmp <- data.frame(nsubj.ped=nsubj.ped) # just to take care of annoying texmaker bug
age.ped <- data.frame(Age=data.ped$AgeAtScan/365.25)

myhist <- ggplot(age.ped, aes(x=Age))
myhist + geom_histogram(binwidth=1) + labs(title="Age Distribution of Pediatric Subjects") + 
  theme(axis.title=element_text(size=24), plot.title=element_text(size=36), 
        axis.text.x=element_text(size=18), axis.text.y=element_text(size=18)) + 
        scale_x_continuous(breaks=seq(6, 18, by=2))
ggsave('fig/pediatric_ages.pdf', width=25, height=15, units='cm')
@

\subsubsection{Pediatric Data:} Our pediatric data consists of \Sexpr{tmp$nsubj.ped} subjects, with mean age \Sexpr{mean(age.ped$Age)}, range \Sexpr{min(age.ped$Age)}-\Sexpr{max(age.ped$Age)} years (Figure \ref{fig:hist_ages}).  Magnetization-Prepared Rapid Acquisition Gradient Echo (MPRAGE) images were acquired using a 3D inversion recovery sequence with TR/TE/TI = 2170/4.33/1100 ms.  The resolution was 1x1x1mm$^2$ with a matrix size of 256x256x192. Flip angle = $7\,^{\circ}$ and total scan time was 8:08 minutes.  Pseudo continuous arterial spin labeled (pCASL) images were acquired using TR/TE = 4000/22 ms, with resolution of 3.125x3.125x6mm$^3$ over a 64x64x24 matrix. 40 label/control pairs were acquired. Generalized autocalibrating partially parallel acquisition (GRAPPA) was done using  an acceleration factor of 2. Labeling duration was 1.5s and the post-labeling delay was 1.2s. Total imaging time was 5:30 minutes. 
\begin{figure}
\centering
\includegraphics[width=10cm]{fig/pediatric_ages.pdf}
\caption{Histogram of ages of pediatric population.}
\label{fig:hist_ages}
\end{figure}


\subsubsection{Image Preprocessing:} The set of T1 images from each subject's first time points was used to construct a template using ANTs \cite{avants_reproducible_2011}. Additionally, a three-tissue segmentation of the template \cite{avants_open_2011} allowed the labels to be partially masked so only cortex and deep gray structures were labeled. For each time point, the T1 image was registered to the template image using SyN \cite{avants_symmetric_2008}. The subject's T1 image was also registered to the M0 image acquired as a reference for the pCASL using the \verb=antsIntrasubjectIntermodality.sh= script in ANTs. These transforms were composed to map the cortical labels into ASL native space for each time point. For pCASL images, the M0 image served as a reference for motion-correction of all time-point volumes. Sinc interpolation was used to estimate the full time-series for both the control and tag data. Nuisance parameters, including motion and physiological confounds, were included as regressors, along with the tag-control binary label, in a robust regression scheme for CBF calculation \cite{avants_robust_2012}.   The difference between control and tag was used along with relevant acquisition parameters to calculate the ASL-CBF over time.  Full details are available in the open-source script at \url{https://raw.github.com/stnava/ANTs/master/Scripts/antsASLProcessing.sh}. 

\section{Results}
Before analyzing real neuroimaging data, we first present two synthetic data analyses to provide a greater understanding of the motivation and mechanics of our method.  We demonstrate the operation of the perfusion-anatomy decomposition on simple synthetic images to highlight the effect of orientation invariance when predicting perfusion.  We then perform a simulated population experiment showing how observed changes in perfusion can in fact be due either to the underlying anatomy or changes in perfusion that are not explained by anatomical features.  Following the synthetic experiments, we show that our anatomical features are much better than tissue probability maps or cortical thickness at predicting perfusion, and that both the anatomically predicted and residual functional images are highly reproducible within subjects.  Finally, we demonstrate that the anatomically predicted and residual CBF signals in a pediatric population are tightly correlated with age in a region-specific manner, and that in certain instances have opposing trends.  

\subsection{Synthetic Image Decomposition}
<<synthetic, echo=FALSE, eval=FALSE, warning=FALSE, results='hide'>>=
suppressMessages(require(ANTsR))
system("~/bin/PatchAnalysis/PatchAnalysis -i data/imgs/Structural.nii.gz -m data/imgs/Structural.nii.gz -e data/test_eig -p data/projectedOrientationInvariant -o ")
t1 <- antsImageRead('data/imgs/Structural.nii.gz', 2)
asl <- antsImageRead('data/imgs/Functional.nii.gz', 2)
plotANTsImage(t1, outname='fig/SyntheticStructural.png')
plotANTsImage(asl, outname='fig/SyntheticFunctional.png')
coeffs <- t(as.array(antsImageRead('data/projectedOrientationInvariant.mha', 2)))
class(coeffs) <- "numeric"
mask <- antsImageRead('data/imgs/Structural.nii.gz', 2)
asl.data = asl[mask > 0]
mydata <- data.frame(asl=asl.data, coeffs=coeffs)
myformula <- "asl ~ coeffs.1"
for( i in 3:length(names(mydata))){
  myformula <- paste(myformula, '+', names(mydata)[i])
}
mylm <- lm(myformula, data=mydata)
summary(mylm)
asl.functional <- antsImageClone(t1)
asl.functional[mask>0] <- residuals(mylm)
antsImageWrite(asl.functional, 'data/imgs/OnlyFunctionOrientationInvariant.nii.gz')
plotANTsImage(asl.functional, outname='fig/OnlyFunctionOrientationInvariant.png')
asl.struct <- antsImageClone(t1)
asl.struct[mask>0] <- mylm$fitted.values
antsImageWrite(asl.struct, 'FunctionFromStructureOrientationInvariant.nii.gz')
plotANTsImage(asl.struct, outname='fig/FunctionFromStructureOrientationInvariant.png')



system("~/bin/PatchAnalysis/PatchAnalysis -i data/imgs/Structural.nii.gz -m data/imgs/Structural.nii.gz -e data/OrientationInvariantEig -p data/projectedOrientationVariant ")
t1 <- antsImageRead('data/imgs/Structural.nii.gz', 2)
asl <- antsImageRead('data/imgs/Functional.nii.gz', 2)
coeffs.var <- t(as.array(antsImageRead('data/projectedOrientationVariant.mha', 2)))
class(coeffs.var) <- "numeric"
mask <- antsImageRead('data/imgs/Structural.nii.gz', 2)
asl.data = asl[mask > 0]
mydata <- data.frame(asl=asl.data, coeffs=coeffs.var)
myformula <- "asl ~ coeffs.1"
for( i in 3:length(names(mydata))){
  myformula <- paste(myformula, '+', names(mydata)[i])
}
mylm <- lm(myformula, data=mydata)
summary(mylm)
asl.functional <- antsImageClone(t1)
asl.functional[mask>0] <- residuals(mylm)
antsImageWrite(asl.functional, 'data/imgs/OnlyFunctionOrientationVariant.nii.gz')
plotANTsImage(asl.functional, outname='fig/OnlyFunctionalOrientationVariant.png')
asl.struct <- antsImageClone(t1)
asl.struct[mask>0] <- mylm$fitted.values
antsImageWrite(asl.struct, 'data/imgs/FunctionFromStructureOrientationVariant.nii.gz')
plotANTsImage(asl.struct, outname='fig/FunctionFromStructureOrientationVariant.png')

@

\begin{figure}
\centering
  \begin{subfigure}[t]{4cm}
    \includegraphics[width=4cm]{fig/SyntheticStructural.png}
    \caption{Synthetic anatomical data.}
  \end{subfigure}
  \hspace{1em}
  \begin{subfigure}[t]{4cm}
    \includegraphics[width=4cm]{fig/SyntheticFunctional.png}
    \caption{Synthetic perfusion data.}
    \label{fig:synthetic_functional}
  \end{subfigure}
  \hspace{1em}
  \begin{subfigure}[t]{4cm}
    \includegraphics[width=4cm]{fig/FunctionFromStructureOrientationVariant.png}
    \caption{Perfusion signal that can be reproduced from anatomy, using non-orientation invariant features.}
    \label{fig:function_structure_orientation_variant}
  \end{subfigure}
  \hspace{1em}
  \begin{subfigure}[t]{4cm}
    \includegraphics[width=4cm]{fig/OnlyFunctionalOrientationVariant.png}
    \caption{Residual perfusion signal, analyzed using non-orientation invariant features. }
    \label{fig:only_function_orientation_variant}
  \end{subfigure}
  \hspace{1em}
  \begin{subfigure}[t]{4cm}
    \includegraphics[width=4cm]{fig/FunctionFromStructureOrientationInvariant.png}
    \caption{Perfusion signal that can be reproduced from anatomy, using orientation invariant features.}
    \label{fig:function_structure_orientation_invariant}
  \end{subfigure}
  \hspace{1em}
  \begin{subfigure}[t]{4cm}
    \includegraphics[width=4cm]{fig/OnlyFunctionOrientationInvariant.png}
    \caption{Residual perfusion signal, analyzed using orientation invariant features.}
    \label{fig:only_functional_orientation_invariant}
  \end{subfigure}

\caption{Synthetic perfusion and anatomical data.  Some aspects of the perfusion data, such as the higher activity at the intersection of the lines, can be deduced from the underlying anatomy (the intersection of the lines), but other aspects of the perfusion data, such as the increased activity on the upper right line, cannot be deduced from the anatomy. \ref{fig:only_function_orientation_variant},\ref{fig:function_structure_orientation_variant}: Decomposition of synthetic data using non-rotational invariant features.  The constructed features include orientation, so the higher values in the horizontal line are correctly reconstructed. \ref{fig:only_functional_orientation_invariant}, \ref{fig:function_structure_orientation_invariant}: Reconstructed perfusion and residual perfusion decomposition of Figure \ref{fig:synthetic_functional}.  Because orientation invariant features were used, the higher perfusion of the horizontal line is not predicted, but the intersection of the lines does indicate a greater predicted functional signal.  Orientation invariance enables greater information sharing across regions, leading to lower variance in the reconstruction as compared to the reconstruction using non-rotationally invariant features \ref{fig:function_structure_orientation_variant}. }
\label{fig:synthetic_decomposition}
\end{figure}

We generated synthetic data to demonstrate how the proposed method decomposes simulated functional images into its purely functional component and to the component that can be inferred from structure. Figure \ref{fig:synthetic_decomposition} shows the ``anatomical'' and ``perfusion'' components of the data.  Some aspects of the perfusion data, such as the increased activity at the intersections of the lines, can be inferred from the structure of the image (when trained on an appropriate reference functional image).  Other aspects of the functional data, such as the increased activity on the upper right-hand line, cannot be inferred from the structural data: Given a patch-based descriptor of a given voxel in the structural image, it is impossible to tell whether the corresponding perfusion voxel has a high or low value.  In addition, certain functional values can only be inferred from the orientation of the structure.  For example, the horizontal central line has a higher functional value than the vertical lines.  Given only an orientation-invariant feature description of the central line, it is impossible to tell what the functional value is. Figure \ref{fig:synthetic_decomposition} shows the result of the decomposition.  As we would expect, both decompositions do not predict the increased activity in the upper right-hand line from the structural data, but do reconstruct the increased activity at the intersections of the lines.  Only the non-rotation invariant decomposition reconstructs the increased activity on the horizontal line.  On the other hand, constructing orientation-invariant features enables sharing more data across regions, leading to a lower-variance reconstruction (Figure \ref{fig:function_structure_orientation_invariant}).  We consider the structure of neuroimaging data to be ``rotation-invariant'' in the sense that a gyrus pointing superiorly is equivalent to a gyrus pointing inferiorly.  This rotation invariance enables information to be shared across hemispheres of the brain and reduces the chances of overfitting to a specific region. 

\subsection{Simulated Population Study}
<<plotBlobs, echo=FALSE, eval=FALSE>>=
atlas          <- antsImageRead('data/simulation/mni.nii.gz', 3)
structblob     <- antsImageRead('data/simulation/structblob_smooth.nii.gz', 3)
funcblob       <- antsImageRead('data/simulation/funcblob_smooth.nii.gz', 3)
structfuncblob <- antsImageRead('data/simulation/structfuncblob_smooth.nii.gz', 3)
sample         <- antsImageRead('data/simulation/imgs/perfusion01.nii.gz', 3)
structpmap <- antsImageRead('data/simulation/vbm/struct1minuspValues_corrected.nii.gz', 3)
funcpmap   <- antsImageRead('data/simulation/vbm/func1minuspValues_corrected.nii.gz', 3)
perfmap   <- antsImageRead('data/simulation/vbm/perfusion1minuspValues_corrected.nii.gz', 3)

plotANTsImage(atlas, axis=3, functional=list(structblob, funcblob, structfuncblob),
              threshold="150x260", 
              color=c("red", "green", "blue"), slices="30x140x6", 
              outname="fig/blobs.jpg", quality=5)
plotANTsImage(sample, axis=3, threshold="0x255", slices="30x140x6", 
              outname='fig/sample_sim.jpg', quality=5)

plotANTsImage(atlas, axis=3, functional=list(structpmap), 
                threshold="243x255", color="red", slices="30x140x6", 
                outname='fig/structpmap.jpg', quality=5)
plotANTsImage(atlas, axis=3, functional=list(funcpmap), 
                threshold="243x255", color="red", slices="30x140x6", 
              outname='fig/funcpmap.jpg', quality=5)
plotANTsImage(atlas, axis=3, functional=list(perfmap), 
              threshold="243x255", color="red", slices="30x140x6", 
              outname='fig/perfmap.jpg', quality=5)
@

To demonstrate the need for a structure-function decomposition that differentiates between differences in perfusion that are due to structural differences and those that are due to functional differences, we constructed a simulated data set that includes structural and functional effects.  Throughout the brain, we simulated an ASL perfusion image based on the gray and white matter probability maps, with added noise.  Using the notation from Section \ref{sec:struct}, at voxel $x \in \mathcal{I}$:
\begin{equation}
c_{\mathrm{obs}}(x) = 100 \cdot p_{\mathrm{GM}}(x) + 40 \cdot p_{\mathrm{WM}}(x)  + \text{noise}
\end{equation}
To the images in the experimental group, we added additional anatomical and perfusion blobs in the following manner (Figure \ref{fig:simulation}).  In one blob (the ``anatomical'' blob), we increased the probability of gray matter.  This caused a corresponding increase in the perfusion images.  In the second blob, we increased the perfusion without a corresponding increase in GM probability, creating a perfusion increase that does not have a corresponding structural abnormality.  Denoting CBF that is not predicted from the underlying anatomy as $c_{\mathrm{r}}(x)$, 
\begin{equation}
c_{\mathrm{obs}}(x) = 100 \cdot p_{\mathrm{GM}}(x) + 40 \cdot p_{\mathrm{WM}}(x) + c_{\mathrm{r}}(x) + \text{noise}.
\end{equation}
In the third blob, we increased the GM probability and also added additional perfusion above that predicted by the increased GM probability.  This blob represents an area that has both a structural abnormality (increased GM probability) and a perfusion abnormality (increased perfusion above that predicted by GM content). To recover an anatomy-perfusion decomposition of the images, we regressed out the anatomical information (GM and WM probability maps) from the perfusion images following the method in Section \ref{sec:feature_regression}.  This regression gave us two images:  The perfusion predicted from structure, and the residual functional activation that is not explained by structure, in addition to the original perfusion images. 

We ran a voxelwise t-test comparing control vs. experimental groups on the three types of images.  The results are shown in Figure \ref{fig:simulation}.  Reporting voxelwise $p$-statistic maps on the raw perfusion images shows all three blobs, because all three blobs indeed had increased perfusion in the experimental group (Figure \ref{fig:sim_perfusion}).  $p$-statistic maps on the residual functional images show both the residual perfusion blob and the combined anatomical and perfusion blob (Figure \ref{fig:sim_func}).  This image, however, ignores the potentially biologically important role of decreased perfusion caused by abnormal anatomy.  The $p$-statistic map on the perfusion images as predicted by anatomy shows this missing information (Figure \ref{fig:sim_struct}). 
\begin{figure}
\centering
\begin{subfigure}{\textwidth}
  \includegraphics[width=1\textwidth]{fig/blobs.jpg}
  \caption{Blob locations for simulation population study.  Red is the structural blob, green is the functional blob, and blue is the combined structural and functional blob.}
  \label{fig:blobs}
\end{subfigure}

\begin{subfigure}{\textwidth}
  \includegraphics[width=1\textwidth]{fig/sample_sim.jpg}
  \caption{Sample simulated ASL image showing increased perfusion in the areas corresponding to the three blobs showin Figure \ref{fig:blobs}.}
  \label{fig:sample}
\end{subfigure}

\begin{subfigure}{\textwidth}
  \includegraphics[width=1\textwidth]{fig/perfmap.jpg}
  \caption{$1-p$-value map (FDR corrected) for the raw simulated ASL images.  The structural, functional, and combined functional and structural blobs all appear, making it difficult to discern whether the increase in perfusion is due to a structural or functional change.}
  \label{fig:sim_perfusion}
\end{subfigure}

\begin{subfigure}{\textwidth}
  \includegraphics[width=1\textwidth]{fig/structpmap.jpg}
  \caption{$1-p$-value map (FDR corrected) for the structural component of the perfusion map.  The structural blob (area of increased GM probability) and combined functional and structural blob (both increased GM probability and an additional increase in perfusion) appear, but not the purely functional blob.}
  \label{fig:sim_struct}
\end{subfigure}

\begin{subfigure}{\textwidth}
  \includegraphics[width=\textwidth]{fig/funcpmap.jpg}
  \caption{$1-p$-value map (FDR corrected) for the correlation of the purely functional component of the perfusion map (after regressing out structural effects).  The purely functional blob and the blob with combined structural and functional effects both appear.}
  \label{fig:sim_func}
\end{subfigure}
\caption{Simulated ASL study showing the importance of decomposing observed perfusion images into structural and functional components.}
\label{fig:simulation}

\end{figure}




\subsection{Sample subject}
The mean CBF as well as CBF that can be predicted from structure as well as purely functional CBF, with reconstruction from probability maps for reference, for a sample subject are presented in Figure \ref{fig:sample_subj_imgs}.  The structural CBF provides a better prediction of the raw CBF image, and in particular predicts higher perfusion in sulcal pits.  A quantitative depiction of the correlation between predicted and actual CBF is given in Figure \ref{fig:sample_subj_cor}.

\begin{figure}
\centering
\begin{subfigure}[t]{5cm}
  \includegraphics[height=6cm]{figure/kcbf.png}
  \caption{Raw mean CBF image.}
  \label{fig:sample_kcbf}
\end{subfigure}
\hspace{1em}
\begin{subfigure}[t]{5cm}
  \includegraphics[height=6cm]{figure/structCBF.png}
  \caption{CBF image that can be reconstructed from structure.}
  \label{fig:sample_structCBF}
\end{subfigure}
\hspace{1em}
\begin{subfigure}[t]{5cm}
  \includegraphics[height=6cm]{figure/funcCBF.png}
  \caption{``Functional'' CBF image that cannot be reconstructed from structure.}
  \label{fig:sample_funcCBF}
\end{subfigure}
\hspace{1em}
\begin{subfigure}[t]{5cm}
  \includegraphics[height=6cm]{figure/probCBF.png}
  \caption{CBF image reconstructed using only probability maps.}
  \label{fig:sample_probCBF}
\end{subfigure}
\caption{Comparison of mean CBF image and reconstruction from anatomy, residual perfusion image, and reconstruction from GM and WM probability images.  Mean CBF image is shown at ASL resolution (3.4mmx3.4mmx7.5mm); other images are shown at 1mm isotropic resolution. TODO: Should this be cortex (or GM) only? }
\label{fig:sample_subj_imgs}
\end{figure}

\begin{figure}
\centering 
\begin{subfigure}{6cm}
  \includegraphics[width=7cm]{figure/StructCBF.pdf}
  \caption{Predictions of CBF using our structural predictors.}
  \label{fig:struct_cbf}
\end{subfigure}
\begin{subfigure}{6cm}
  \includegraphics[width=7cm]{figure/ProbCBF.pdf}
  \caption{Prediction of CBF using only probability maps.}
  \label{fig:prob_cbf}
\end{subfigure}
\caption{Predictions of CBF in GM using our structural predictors and probability maps.  Our structural predictors account for much more variance than probability maps, which exhibit a very strong ceiling effect.}
\label{fig:sample_subj_cor}
\end{figure}

\subsection{Variance explained} 
<<TestRetest, eval=booleval>>=
cors <- read.csv('analysis/Predictions.csv')
cors[,1] <- NULL
cors.m <- melt(cors)
colnames(cors.m) <- c('Predictor', 'Correlation')
ggplot(cors.m, aes(Predictor, Correlation)) + geom_boxplot(aes(fill=Predictor)) +
  ylab('Correlation with CBF') + theme(text=element_text(size=25)) + ggtitle('CBF Prediction Accuracy vs. Predictor (GM)')
ggsave('figure/TestRetest.pdf', width=14, height=7)
@

\begin{figure}
\centering 
\includegraphics[width=15cm]{figure/VarianceExplained.pdf}
\caption{CBF prediction accuracy: Performance evaluation of CBF predicting test-retest CBF; probability maps; probability maps and thickness; and our structural predictors in predicting CBF.  Our structural predictors are much better at predicting CBF than probability maps, and account for roughly half the reproducible ASL signal.  This result indicates that our structural predictors are more appropriate for structural correction of perfusion than using only tissue probability maps and cortical thickness.}
\label{fig:variance_explained}
\end{figure}

The structural features we compute are significantly better at predicting perfusion data than gray and white matter probability masks and than cortical thickness maps.  Figure \ref{fig:variance_explained} compares predicted vs.\ actual perfusion values using the proposed method, segmentation probability maps, cortical thickness for the test-retest cohort.  The correlation is computed voxel-wise across the gray matter, and each sample corresponds to one subject.    The higher correlation of our structural predictors with CBF as compared to the controls indicates that our predictors are more effective at explaining observed perfusion than the control predictors. 

\subsection{Reproducibility}
\begin{figure}
\centering
\includegraphics[width=15cm]{figure/Reproducibility.pdf}
\caption{Reproducibility of mean CBF and derived CBF measures.  Reproducibility is reported as the voxelwise correlation of the measure at two scans taken one hour apart.}
\label{fig:reproducibility}
\end{figure}
A key measure of the reliability of a clinical measurement is its test-retest reproducibility within a given subject.  We evaluated the test-retest reproducibility of our anatomically-predicted and residual perfusion images and compared them to the reproducibility of the raw CBF signal and reproducibility of perfusion as predicted by tissue probability maps and cortical thickness.  We evaluated reproducibility by voxel-wise correlation between the images at two time points for a given subject.  We found that the test-retest voxel-wise correlation of CBF was roughly 0.65, and both the anatomically predicted and residual CBF were within 0.1 of that value.  Although the high reproducibility of the structurally predicted CBF was expected, the high reproducibility of the residual CBF indicates that it is not simply random noise and varies in a consistent way across subjects. 

\subsection{Pediatric Population Study}
<<peds_study,echo=FALSE,results='hide',eval=TRUE, warnings=FALSE>>=
suppressMessages(require(ggplot2))
suppressPackageStartupMessages(require(reshape2))
suppressMessages(require(ANTsR))
data(aal)
replot <- FALSE
demog <- read.csv('analysis/DemogWithASLVals_lores.csv')
#myrois <- c(1, 3, 7, 13, 37, 45, 55, 49, 63, 67,  81, 85) # left precuneus
myrois <- c(37, 38, 49, 50, 67, 68) # minimal set--hippocampus, precuneus, occipital, left and right
badsubj <- c(127,66) # to be deleted

peds.stat <- NULL
for (roi in myrois) {
  mydat.age <- data.frame(Age=demog$AgeAtScan[-badsubj],
    RawCBF=demog[, paste('RawCBFVals.Label', roi, sep='')][-badsubj],
    StructCBF=demog[, paste('StructCBFVals.Label', roi, sep='')][-badsubj],
    FuncCBF=demog[, paste('FuncCBFVals.Label', roi, sep='')][-badsubj])
  mydat.age.m <- melt(mydat.age, id="Age")
  mydat.thick <- data.frame(Thick=demog[, paste('Thickness_AAL.AAL', roi, sep='')][-badsubj], 
    RawCBF=demog[, paste('RawCBFVals.Label', roi, sep='')][-badsubj],
    StructCBF=demog[, paste('StructCBFVals.Label', roi, sep='')][-badsubj],
    FuncCBF=demog[, paste('FuncCBFVals.Label', roi, sep='')][-badsubj])    
  mydat.thick.m <- melt(mydat.thick, id="Thick")
  colnames(mydat.age.m) <- c('Age', 'Measurement', 'Value')
  colnames(mydat.thick.m) <- c('Thickness', 'Measurement', 'Value')
  if(replot){
    ggplot(mydat.age.m, aes(Age, Value, colour=Measurement)) + geom_point(na.rm=T) +
      geom_smooth(method="lm", na.rm=T) + ggtitle(paste('Functional, Structural, PVC, and Raw CBF vs. Age for', aal$label_name[roi])) +
      xlab('Age (years)') + ylab('CBF (ml/100g/min)') + theme(text=element_text(size=20)) + ylim(-50, 200)
    ggsave(paste('figure/FunctionalStructuralDecomposition', aal$label_name[roi], '.pdf', sep=''),
      width=14, height=7)
    ggplot(mydat.thick.m, aes(Thickness, Value, colour=Measurement)) + geom_point(na.rm=T) + 
      geom_smooth(method='lm', na.rm=T) + xlab('Thickness (mm)') +
      ylab('CBF (ml/100g/min') + 
      ggtitle(paste('Raw, Structurally Predicted, and Residual CBF vs. Cortical Thickness for', aal$label_name[roi]))
    ggsave(paste('figure/CBFVsThickness', aal$label_name[roi], '.pdf', sep=''), 
      width=14, height=7)
  }
  func.lm   <- summary(lm(mydat.age$FuncCBF ~ mydat.age$Age))$coefficients
  struct.lm <- summary(lm(mydat.age$StructCBF ~ mydat.age$Age))$coefficients
  raw.lm    <- summary(lm(mydat.age$RawCBF ~ mydat.age$Age))$coefficients
  functhick.lm   <- summary(lm(mydat.thick$FuncCBF ~ mydat.thick$Thick))$coefficients
  structthick.lm <- summary(lm(mydat.thick$StructCBF ~ mydat.thick$Thick))$coefficients
  rawthick.lm    <- summary(lm(mydat.thick$RawCBF ~ mydat.thick$Thick))$coefficients 
  myroi.dataframe <- data.frame(
      FuncAgeEst=func.lm[2,'Estimate'], FuncAgeStE=func.lm[2, 'Std. Error'], FuncAgePVal=func.lm[2, 'Pr(>|t|)'], 
      StructAgeEst=struct.lm[2,'Estimate'], StructAgeStE=struct.lm[2, 'Std. Error'], StructAgePVal=struct.lm[2, 'Pr(>|t|)'], 
      RawAgeEst=raw.lm[2,'Estimate'], RawAgeStE=raw.lm[2, 'Std. Error'], RawAgePVal=raw.lm[2, 'Pr(>|t|)'], 
      FuncThickEst=functhick.lm[2, 'Estimate'], FuncThickSte=functhick.lm[2, 'Std. Error'], FuncThickPVal=functhick.lm[2, 'Pr(>|t|)'], 
      StructThickEst=structthick.lm[2, 'Estimate'], StructThickSte=structthick.lm[2, 'Std. Error'], 
                                                                                        StructThickPVal=structthick.lm[2, 'Pr(>|t|)'], 
      RawThickEst=rawthick.lm[2, 'Estimate'], RawThickSte=rawthick.lm[2, 'Std. Error'], RawThickPVal=rawthick.lm[2, 'Pr(>|t|)'])
  rownames(myroi.dataframe) <-aal$label_name[roi]
  peds.stat <- rbind(peds.stat, myroi.dataframe)
}
@
\begin{figure}
\centering
\begin{subfigure}{11cm}
  \includegraphics[width=11cm]{figure/FunctionalStructuralDecompositionHippocampus_L.pdf}
  \caption{Structural and functional CBF for left hippocampus.}
\end{subfigure}
\begin{subfigure}{11cm}
  \includegraphics[width=11cm]{figure/FunctionalStructuralDecompositionPrecuneus_L.pdf}
  \caption{Structural and functional CBF for left precuneus.}
\end{subfigure}
\begin{subfigure}{11cm}
  \includegraphics[width=11cm]{figure/FunctionalStructuralDecompositionOccipital_Sup_L.pdf}
  \caption{Structural and functional CBF for left occipital lobe.}
\end{subfigure}
\caption{Raw, anatomically predicted, and residual CBF as a function of age.  The raw CBF signal contains a mixture of the structural and functional CBF signals,  which do not necessarily trend in the same direction as raw CBF.}
\label{fig:population}
\end{figure}

\begin{table}
\centering 
\makebox[\textwidth]{
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{2}{c}{Raw CBF} & \phantom{a} & \multicolumn{2}{c}{Structural CBF} & \phantom{a} & \multicolumn{2}{c}{Residual CBF} \\
\cmidrule{2-3} \cmidrule{5-6} \cmidrule{8-9}
& Slope & \textit{p}-value & & Slope & \textit{p}-value & & Slope & \textit{p}-value \\
\midrule  
Left Hippocampus & \Sexpr{peds.stat['Hippocampus_L', 'RawAgeEst']}$\pm$\Sexpr{peds.stat['Hippocampus_L', 'RawAgeStE']} & \Sexpr{peds.stat['Hippocampus_L', 'RawAgePVal']} & & 
\Sexpr{peds.stat['Hippocampus_L', 'StructAgeEst']}$\pm$\Sexpr{peds.stat['Hippocampus_L', 'StructAgeStE']} & 
\Sexpr{peds.stat['Hippocampus_L', 'StructAgePVal']} & & 
\Sexpr{peds.stat['Hippocampus_L', 'FuncAgeEst']}$\pm$\Sexpr{peds.stat['Hippocampus_L', 'FuncAgeStE']} & 
\Sexpr{peds.stat['Hippocampus_L', 'FuncAgePVal']} \\
Right Hippocampus & \Sexpr{peds.stat['Hippocampus_R', 'RawAgeEst']}$\pm$\Sexpr{peds.stat['Hippocampus_R', 'RawAgeStE']} & \Sexpr{peds.stat['Hippocampus_R', 'RawAgePVal']} & & 
\Sexpr{peds.stat['Hippocampus_R', 'StructAgeEst']}$\pm$\Sexpr{peds.stat['Hippocampus_R', 'StructAgeStE']} & 
\Sexpr{peds.stat['Hippocampus_R', 'StructAgePVal']} & & 
\Sexpr{peds.stat['Hippocampus_R', 'FuncAgeEst']}$\pm$\Sexpr{peds.stat['Hippocampus_R', 'FuncAgeStE']} & 
\Sexpr{peds.stat['Hippocampus_R', 'FuncAgePVal']} \\
Left Precuneus & \Sexpr{peds.stat['Precuneus_L', 'RawAgeEst']}$\pm$\Sexpr{peds.stat['Precuneus_L', 'RawAgeStE']} & \Sexpr{peds.stat['Precuneus_L', 'RawAgePVal']} & & 
\Sexpr{peds.stat['Precuneus_L', 'StructAgeEst']}$\pm$\Sexpr{peds.stat['Precuneus_L', 'StructAgeStE']} & 
\Sexpr{peds.stat['Precuneus_L', 'StructAgePVal']} & & 
\Sexpr{peds.stat['Precuneus_L', 'FuncAgeEst']}$\pm$\Sexpr{peds.stat['Precuneus_L', 'FuncAgeStE']} & 
\Sexpr{peds.stat['Precuneus_L', 'FuncAgePVal']} \\
Right Precuneus & \Sexpr{peds.stat['Precuneus_R', 'RawAgeEst']}$\pm$\Sexpr{peds.stat['Precuneus_R', 'RawAgeStE']} & \Sexpr{peds.stat['Precuneus_R', 'RawAgePVal']} & & 
\Sexpr{peds.stat['Precuneus_R', 'StructAgeEst']}$\pm$\Sexpr{peds.stat['Precuneus_R', 'StructAgeStE']} & 
\Sexpr{peds.stat['Precuneus_R', 'StructAgePVal']} & & 
\Sexpr{peds.stat['Precuneus_R', 'FuncAgeEst']}$\pm$\Sexpr{peds.stat['Precuneus_R', 'FuncAgeStE']} & 
\Sexpr{peds.stat['Precuneus_R', 'FuncAgePVal']} \\
Left Occipital & \Sexpr{peds.stat['Occipital_Sup_L', 'RawAgeEst']}$\pm$\Sexpr{peds.stat['Occipital_Sup_L', 'RawAgeStE']} & \Sexpr{peds.stat['Occipital_Sup_L', 'RawAgePVal']} & & 
\Sexpr{peds.stat['Occipital_Sup_L', 'StructAgeEst']}$\pm$\Sexpr{peds.stat['Occipital_Sup_L', 'StructAgeStE']} & 
\Sexpr{peds.stat['Occipital_Sup_L', 'StructAgePVal']} & & 
\Sexpr{peds.stat['Occipital_Sup_L', 'FuncAgeEst']}$\pm$\Sexpr{peds.stat['Occipital_Sup_L', 'FuncAgeStE']} & 
\Sexpr{peds.stat['Occipital_Sup_L', 'FuncAgePVal']} \\
Right Occipital & \Sexpr{peds.stat['Occipital_Sup_R', 'RawAgeEst']}$\pm$\Sexpr{peds.stat['Occipital_Sup_R', 'RawAgeStE']} & \Sexpr{peds.stat['Occipital_Sup_R', 'RawAgePVal']} & & 
\Sexpr{peds.stat['Occipital_Sup_R', 'StructAgeEst']}$\pm$\Sexpr{peds.stat['Occipital_Sup_R', 'StructAgeStE']} & 
\Sexpr{peds.stat['Occipital_Sup_R', 'StructAgePVal']} & & 
\Sexpr{peds.stat['Occipital_Sup_R', 'FuncAgeEst']}$\pm$\Sexpr{peds.stat['Occipital_Sup_R', 'FuncAgeStE']} & 
\Sexpr{peds.stat['Occipital_Sup_R', 'FuncAgePVal']} \\
\bottomrule 
\end{tabular}
}
\caption{Statistics from linear models plotted in Figure \ref{fig:population}.  Although the raw and structurally predicted CBF values showed strong trends with age, the trends for the residual CBF was more variable.  Strong trends were evident in the hippocampus and precuneus, but not in occipital cortex.  Slope is given in units of CBF (ml/100g/min) per year.}
\label{tab:population_stats}
\end{table}

To demonstrate the utility and plausibility of the anatomically predicted and residual CBF in a population study of interest, we examined the dependence of the two signals as a function of age in a large pediatric dataset.  We found that in all regions, raw CBF decreased in a roughly linear fashion with age.  The structurally predicted CBF also decreased with age, but the residual CBF had a regionally varying trend.  In the hippocampus, the residual CBF increased with age; in precuneus, it decreased with age; and in the occipital cortex, it stayed roughly constant.  Plots for the left hemisphere are shown in Figure \ref{fig:population}; trends were roughly symmetric across hemispheres.  Statistical analysis of the dependency on age is given in Table \ref{tab:population_stats}. 

\section{Discussion}
We have presented here a method to separate the anatomically predicted from the residual components of perfusion images as measured by ASL MRI.  Our method to generate structural predictors gives much better prediction accuracy for predicting CBF than either probability maps or cortical thickness.  The test-rest reproducibility of both the structural CBF and the functional CBF is within 10\% of the test-retest reproducibility of ASL, implying that both the structural and functional CBF maps contain stable signals.  In addition, we found that both the anatomically predicted and residual CBF were closely related to age, further implying that both signals reveal true neurobiological processes and are not simply measurement noise. 


\subsection{Interpretation of Structural and Functional CBF}
The method proposed here takes mean CBF values and structural images as input, and produces as output a ``structural'' CBF image and a ``purely functional'' CBF image.  At first glance, the interpretation of these two outputs may be somewhat obscure, but we believe that when properly understood, each image has an intuitively clear interpretation that can be directly incorporated into clinical characterization of a subject.  By way of analogy, we imagine an experiment tracking subject performance on a test of verbal ability in a group of children.  A researcher may regress out ``nuisance variables,'' such as subject age and familial income, before examining the results.  At the group level, the effect of these nuisance variables may in fact be of interest, but looking at an individual's score without accounting for these nuisance variables would be misleading.  In our method, we consider the ``group effects'' to be structural effects shared across the brain, whereas the ``subject-level'' measurements are the perfusion values at a given voxel.  The group effects of underlying brain structure, similarly to age and familial income in our imagined verbal ability study, may be of independent interest, and we may be interested in looking at regional variations in perfusion as predicted by structural measures.  When looking at a given voxel, though, we may also be interested in the amount of perfusion that is not predicted by the underlying neural architecture, just as one may look at a verbal ability result for a given subject when corrected for age and family income.  For both the structural and functional CBF measurements, the units are in the same units of blood flow as the original mean CBF image.  Negative values for the functional CBF image correspond to areas with less-than-expected perfusion as compared to structurally homologous regions elsewhere in the brain. 

\subsection{Results from Population Study}
We examined how structurally predicted and residual CBF vary across age in a pediatric population.  We found that although the raw and structurally predicted CBF decreased across all regions, the trends for residual CBF were not constant.  In the precuneus, the residual CBF decreased with age, whereas in the hippocampus, the residual CBF increased with age.  Although it is premature to draw strong conclusions from this preliminary study, these results suggest that in younger children, the hippocampus is hypoperfused relative to a global model relating structure to CBF, whereas the precuneus is relatively hyperperfused.  In both regions, the trend for residual CBF was towards zero, perhaps indicating that global models more accurately describe the perfusion of older subjects.  On the other hand, there was not a significant trend for the occipital lobe, indicating that the ability of a global model to describe the anatomy-perfusion relationship in the occipital lobe does not significantly change over time.  The finding of more significant trends in the hippocampus and precuneus, both members of the default mode network, may indicate a degree of development of the default mode network over development.  However, a more complete study of the trends is necessary before making any conclusions.  

\subsection{Comparison to Partial Volume Correction Techniques}
Although the method proposed here falls into the general category of atrophy and structure correction techniques, it has a fundamentally different purpose from standard partial volume correction (PVC) techniques \cite{meltzer_correction_1990,muller-gartner_measurement_1992,thomas_importance_2011} which we believe more directly addresses the question of structure and atrophy correction in perfusion imaging.  PVC aims to recover what the scanner \textit{would have seen} had technical impediments, such as partial volume effects, not interfered with the imaging.  In contrast, we aim to recover both the effect of anatomy on the perfusion image and the perfusion that is independent of anatomy.  This technique has two major advantages over PVC-based approaches.  First, PVC-based approaches typically rely on strong \textit{a priori} knowledge or assumptions about scanner mechanics and tissue properties.  In particular, the assumption of standard ASL PVE techniques that white matter perfusion is 40\% of gray matter perfusion for all subjects is a particularly specious assumption, as even the original study that established that value showed significant variations within control populations \cite{roberts_quantitative_1994}.  In contrast, our method learns the relation between brain structure and perfusion implicitly from the data and is agnostic with respect to scanner properties and modality.  Second, our method approaches the problem of atrophy and structure correction more directly than PVC-based techniques and can yield more biologically meaningful results.  Instead of assuming that the relation between observed perfusion and structure is mediated solely by tissue membership and scanner properties, our approach can model more subtle effects of brain structure that elude standard PVC-based approaches. Similarly, as opposed to PVE-based approaches, which are designed to correct GM perfusion values, our approach can apply to any tissue type.   

\subsection{Consideration of Resolution}
The different resolutions of arterial spin labeling MRI as compared to T1 MRI present significant challenges when attempting to analyze the relationship between the two modalities.  Because the T1 image is at a much higher resolution than the ASL image, it is difficult to disentangle the effects of scanner characteristics on observed perfusion from true perfusion results.  As opposed to PET imaging, quantitative analysis of ASL scanners using physical or computational phantoms is not widespread, although some initial efforts have been reported \cite{noguchi_quantitative_2007}.  The lack of quantitative tools for analyzing scanner properties complicates the effort to work across resolutions.  To examine the effect of anatomical variation on observed perfusion, we upsampled the ASL images to T1 resolution and corrected in the T1 resolution, as the T1 resolution gives the most information about the underlying anatomy.  On the other hand, upsampling can introduce artifacts of its own and may not be ideal for all studies.  Especially when looking at larger cortical features than those considered here, working at a lower resolution may be more appropriate.   

\subsection{Limitations}
Although this work demonstrates that the proposed method has promise, it does leave some unanswered questions that require further study. First, although the results in the pediatric population imply that the signal present in the functional CBF has biological significance, more study is necessary to validate this finding in a variety of populations to further elucidate its utility in broader applications. Second, we have not rigorously examined here how the dictionaries and coefficients vary across patients.  Using only the predicted value from the dictionary learning approach without examining how the predictions are made may in fact throw away useful data, as the global  relationship between structure and perfusion may contain biologically significant information.  To compare the structure-CBF relationship across subjects, though, it would be necessary to learn a consistent dictionary and apply it to all subjects.  Carefully examining the variability of learned dictionaries across subjects and across different populations is necessary to establish appropriate techniques for constructing population-wide dictionaries.  

\subsection{Future Work}
\subsubsection{Variations of the Technique}
In this work, we learned the relationship between brain structure and perfusion on a per-subject basis.  The motivation for this is that although there may be global variations in the function that relates brain structure and perfusion, the function is a global signal over the entire brain, whereas the use of imaging is intended to highlight regionally varying measures of perfusion.  This correction for global signal changes is similar in spirit to the use of relative CBF \cite{aslan_sensitivity_2010}, where correcting for global perfusion has been found to increase the ability to find regional differences in blood flow.   For application to patient populations, though, it may be more appropriate to learn the structure-perfusion relationship in an age-matched control cohort and apply the structure correction to the patient population.  

A related question that this study raises is how the structure-perfusion relationship changes across the brain.  It may be more appropriate to learn the structure-perfusion relationship across individual lobes, rather than over the entire brain.  

\subsubsection{Additional Applications}
Although this study is limited to the connection between brain structure and perfusion, the method is fundamentally agnostic to imaging modality and can be applied across a wide range of imaging techniques.  An obvious application of this work is atrophy correction for neurodegenerative populations.  Although several studies have shown that brain perfusion, as measured by ASL imaging, decreases in Alzheimer's Disease \cite{wolk_arterial_2012}, the extent to which this decrease could be determined by atrophic and other structural changes has not been addressed using methods similar to the proposed work. 

\section{Conclusion}
The method presented here shows promise in decomposing CBF images into anatomically predicted and residual perfusion components.  The algorithm proposed explains significantly more of the variance in CBF images than the segmentation probability maps commonly used for performing partial volume correction, and therefore may be more suitable for structural correction of perfusion images than tissue segmentation images. 

\bibliographystyle{elsarticle-num}
\bibliography{kandel_lib}
\end{document}
